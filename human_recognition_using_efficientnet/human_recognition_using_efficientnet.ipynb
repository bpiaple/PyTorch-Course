{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Human Recognition Using Efficientnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make some imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.4.1+cu121\n",
      "torchvision version: 0.19.1+cu121\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torchvision\n",
    "from torchvision.transforms import v2 as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "print(\"torch version:\", torch.__version__)\n",
    "print(\"torchvision version:\", torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy import short\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a COCO-pretrained YOLO11n model\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Train the model on the COCO8 example dataset for 100 epochs\n",
    "# results = model.train(data=\"coco8.yaml\", epochs=100, imgsz=640)\n",
    "\n",
    "# Run inference with the YOLO11n model on the 'bus.jpg' image\n",
    "# results = model(\"image_1.jpg\", show=True, save=True, save_dir=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in classification-person-4 to yolov11:: 100%|██████████| 19497/19497 [00:01<00:00, 13769.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to classification-person-4 in yolov11:: 100%|██████████| 833/833 [00:00<00:00, 12185.22it/s]\n"
     ]
    }
   ],
   "source": [
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"H6wyTkj7PBYENPzBrhON\")\n",
    "project = rf.workspace(\"piaple-brice-aupe9\").project(\"classification-person\")\n",
    "version = project.version(4)\n",
    "dataset = version.download(\"yolov11\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# # Train the model on the dataset\n",
    "# results = model.train(data=f\"{dataset.location}/data.yaml\", epochs=100, imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = \"/media/etudiant/New D/PyTorchSRC/github_pytorch/PyTorch-Course/human_recognition_using_efficientnet/runs/content/runs/detect/train/weights/best.pt\"\n",
    "\n",
    "model = YOLO(model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /media/etudiant/New D/PyTorchSRC/github_pytorch/PyTorch-Course/human_recognition_using_efficientnet/image_1.jpg: 640x640 2 Sushis, 69.5ms\n",
      "Speed: 1.7ms preprocess, 69.5ms inference, 0.6ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Results saved to \u001b[1mruns/detect/predict3\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results1 = model(\"image_1.jpg\", save=True, save_dir=\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_images = [\n",
    "    [ \"examples/image_1.jpg\", 0.25],\n",
    "    [ \"examples/image_2.jpg\", 0.25],\n",
    "    [ \"examples/image_3.jpg\", 0.25],\n",
    "    [ \"examples/image_4.jpg\", 0.25],\n",
    "    [ \"examples/image_5.jpg\", 0.25],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7879\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7879/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 5.0.0, however version 5.0.1 is available, please upgrade. \n",
      "--------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 1 Pizza, 180.0ms\n",
      "Speed: 4.8ms preprocess, 180.0ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x480 1 Pizza, 166.9ms\n",
      "Speed: 3.6ms preprocess, 166.9ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x640 (no detections), 192.7ms\n",
      "Speed: 4.4ms preprocess, 192.7ms inference, 1.1ms postprocess per image at shape (1, 3, 640, 640)\n",
      "\n",
      "0: 640x640 1 Pizza, 194.4ms\n",
      "Speed: 4.9ms preprocess, 194.4ms inference, 2.4ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import PIL.Image as Image\n",
    "\n",
    "from ultralytics import ASSETS, YOLO\n",
    "\n",
    "# def predict_image(img, conf_threshold, iou_threshold):\n",
    "#     results = model(\n",
    "#         source=img,\n",
    "#         conf=conf_threshold,\n",
    "#         iou=iou_threshold,\n",
    "#         show_labels=True,\n",
    "#         show_conf=True,\n",
    "#     )\n",
    "#     return results[0].plot(font=\"Arial\", font_size=18) if results else None\n",
    "\n",
    "\n",
    "def predict_image(img, \n",
    "                  conf_threshold, \n",
    "                #   iou_threshold\n",
    "                  ):\n",
    "    \"\"\"Predicts objects in an image using a YOLO11 model with adjustable confidence and IOU thresholds.\"\"\"\n",
    "    results = model(\n",
    "        source=img,\n",
    "        conf=conf_threshold,\n",
    "        # iou=iou_threshold,\n",
    "        show_labels=True,\n",
    "        show_conf=True,\n",
    "        imgsz=640,\n",
    "    )\n",
    "\n",
    "    for r in results:\n",
    "        im_array = r.plot()\n",
    "        im = Image.fromarray(im_array[..., ::-1])\n",
    "\n",
    "    return im\n",
    "\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=predict_image,\n",
    "    inputs=[\n",
    "        gr.Image(type=\"pil\", label=\"Téléverser une image\"),\n",
    "        gr.Slider(minimum=0, maximum=1, value=0.25, label=\"Taux de confiance\"),\n",
    "        # gr.Slider(minimum=0, maximum=1, value=0.45, label=\"Seuil d'intersection sur l'union\"),\n",
    "    ],\n",
    "    outputs=gr.Image(type=\"pil\", label=\"Resultat\"),\n",
    "    title=\"Brice Piaple Dada\",\n",
    "    description=\"Detecteur de personnes, sushi, pizza et steak\",\n",
    "\n",
    "    \n",
    "    examples=example_images,\n",
    "\n",
    "    clear_btn=\"Effacer\",\n",
    "    submit_btn=\"Predire\"\n",
    "    \n",
    ")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    iface.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pytorch model\n",
    "model_2 = YOLO(\"yolo11n.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YOLO(\n",
       "  (model): DetectionModel(\n",
       "    (model): Sequential(\n",
       "      (0): Conv(\n",
       "        (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (1): Conv(\n",
       "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (2): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(16, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(8, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): Conv(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (4): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(96, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): Conv(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (6): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): C3k(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv3): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (m): Sequential(\n",
       "              (0): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): Conv(\n",
       "        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (8): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): C3k(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv3): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (m): Sequential(\n",
       "              (0): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): SPPF(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)\n",
       "      )\n",
       "      (10): C2PSA(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): Sequential(\n",
       "          (0): PSABlock(\n",
       "            (attn): Attention(\n",
       "              (qkv): Conv(\n",
       "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (proj): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): Identity()\n",
       "              )\n",
       "              (pe): Conv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "            (ffn): Sequential(\n",
       "              (0): Conv(\n",
       "                (conv): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): Identity()\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (12): Concat()\n",
       "      (13): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): Upsample(scale_factor=2.0, mode='nearest')\n",
       "      (15): Concat()\n",
       "      (16): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(96, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (17): Conv(\n",
       "        (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (18): Concat()\n",
       "      (19): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): Bottleneck(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (20): Conv(\n",
       "        (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "        (act): SiLU(inplace=True)\n",
       "      )\n",
       "      (21): Concat()\n",
       "      (22): C3k2(\n",
       "        (cv1): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (cv2): Conv(\n",
       "          (conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "          (act): SiLU(inplace=True)\n",
       "        )\n",
       "        (m): ModuleList(\n",
       "          (0): C3k(\n",
       "            (cv1): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv2): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (cv3): Conv(\n",
       "              (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (m): Sequential(\n",
       "              (0): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "              (1): Bottleneck(\n",
       "                (cv1): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "                (cv2): Conv(\n",
       "                  (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                  (act): SiLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (23): Detect(\n",
       "        (cv2): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Conv(\n",
       "              (conv): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (1): Conv(\n",
       "              (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "              (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "              (act): SiLU(inplace=True)\n",
       "            )\n",
       "            (2): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (cv3): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
       "                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(128, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
       "                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (1): Sequential(\n",
       "              (0): DWConv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=80, bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "              (1): Conv(\n",
       "                (conv): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)\n",
       "                (act): SiLU(inplace=True)\n",
       "              )\n",
       "            )\n",
       "            (2): Conv2d(80, 80, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "        (dfl): DFL(\n",
       "          (conv): Conv2d(16, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchviz in /media/etudiant/New D/PyTorchSRC/.venv/lib/python3.12/site-packages (0.0.2)\n",
      "Requirement already satisfied: torch in /media/etudiant/New D/PyTorchSRC/.venv/lib/python3.12/site-packages (from torchviz) (2.4.1)\n",
      "Requirement already satisfied: graphviz in /media/etudiant/New D/PyTorchSRC/.venv/lib/python3.12/site-packages (from torchviz) (0.20.3)\n",
      "Requirement already satisfied: filelock in /media/etudiant/New D/PyTorchSRC/.venv/lib/python3.12/site-packages (from torch->torchviz) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /media/etudiant/New D/PyTorchSRC/.venv/lib/python3.12/site-packages (from torch->torchviz) (4.12.2)\n",
      "Requirement already satisfied: sympy in /media/etudiant/New D/PyTorchSRC/.venv/lib/python3.12/site-packages (from torch->torchviz) (1.13.2)\n",
      "Requirement already satisfied: networkx in /media/etudiant/New D/PyTorchSRC/.venv/lib/python3.12/site-packages (from torch->torchviz) (3.3)\n",
      "Requirement already satisfied: jinja2 in /media/etudiant/New D/PyTorchSRC/.venv/lib/python3.12/site-packages (from torch->torchviz) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /media/etudiant/New D/PyTorchSRC/.venv/lib/python3.12/site-packages (from torch->torchviz) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in /media/etudiant/New D/PyTorchSRC/.venv/lib/python3.12/site-packages (from torch->torchviz) (74.1.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /media/etudiant/New D/PyTorchSRC/.venv/lib/python3.12/site-packages (from torch->torchviz) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /media/etudiant/New D/PyTorchSRC/.venv/lib/python3.12/site-packages (from torch->torchviz) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /media/etudiant/New D/PyTorchSRC/.venv/lib/python3.12/site-packages (from torch->torchviz) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /media/etudiant/New D/PyTorchSRC/.venv/lib/python3.12/site-packages (from torch->torchviz) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /media/etudiant/New D/PyTorchSRC/.venv/lib/python3.12/site-packages (from torch->torchviz) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /media/etudiant/New D/PyTorchSRC/.venv/lib/python3.12/site-packages (from torch->torchviz) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /media/etudiant/New D/PyTorchSRC/.venv/lib/python3.12/site-packages (from torch->torchviz) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /media/etudiant/New D/PyTorchSRC/.venv/lib/python3.12/site-packages (from torch->torchviz) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /media/etudiant/New D/PyTorchSRC/.venv/lib/python3.12/site-packages (from torch->torchviz) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /media/etudiant/New D/PyTorchSRC/.venv/lib/python3.12/site-packages (from torch->torchviz) (2.20.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /media/etudiant/New D/PyTorchSRC/.venv/lib/python3.12/site-packages (from torch->torchviz) (12.1.105)\n",
      "Requirement already satisfied: triton==3.0.0 in /media/etudiant/New D/PyTorchSRC/.venv/lib/python3.12/site-packages (from torch->torchviz) (3.0.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /media/etudiant/New D/PyTorchSRC/.venv/lib/python3.12/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->torchviz) (12.6.68)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /media/etudiant/New D/PyTorchSRC/.venv/lib/python3.12/site-packages (from jinja2->torch->torchviz) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /media/etudiant/New D/PyTorchSRC/.venv/lib/python3.12/site-packages (from sympy->torch->torchviz) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                                            Param #\n",
       "==========================================================================================\n",
       "YOLO                                                              --\n",
       "├─DetectionModel: 1-1                                             --\n",
       "│    └─Sequential: 2-1                                            --\n",
       "│    │    └─Conv: 3-1                                             (464)\n",
       "│    │    └─Conv: 3-2                                             (4,672)\n",
       "│    │    └─C3k2: 3-3                                             (6,640)\n",
       "│    │    └─Conv: 3-4                                             (36,992)\n",
       "│    │    └─C3k2: 3-5                                             (26,080)\n",
       "│    │    └─Conv: 3-6                                             (147,712)\n",
       "│    │    └─C3k2: 3-7                                             (87,040)\n",
       "│    │    └─Conv: 3-8                                             (295,424)\n",
       "│    │    └─C3k2: 3-9                                             (346,112)\n",
       "│    │    └─SPPF: 3-10                                            (164,608)\n",
       "│    │    └─C2PSA: 3-11                                           (249,728)\n",
       "│    │    └─Upsample: 3-12                                        --\n",
       "│    │    └─Concat: 3-13                                          --\n",
       "│    │    └─C3k2: 3-14                                            (111,296)\n",
       "│    │    └─Upsample: 3-15                                        --\n",
       "│    │    └─Concat: 3-16                                          --\n",
       "│    │    └─C3k2: 3-17                                            (32,096)\n",
       "│    │    └─Conv: 3-18                                            (36,992)\n",
       "│    │    └─Concat: 3-19                                          --\n",
       "│    │    └─C3k2: 3-20                                            (86,720)\n",
       "│    │    └─Conv: 3-21                                            (147,712)\n",
       "│    │    └─Concat: 3-22                                          --\n",
       "│    │    └─C3k2: 3-23                                            (378,880)\n",
       "│    │    └─Detect: 3-24                                          (464,912)\n",
       "==========================================================================================\n",
       "Total params: 2,624,080\n",
       "Trainable params: 0\n",
       "Non-trainable params: 2,624,080\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# visualize model\n",
    "%pip install torchviz\n",
    "from torchinfo import summary\n",
    "\n",
    "summary(model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_3 = model_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING ⚠️ torch.Tensor inputs should be normalized 0.0-1.0 but max value is 5.17893123626709. Dividing input by 255.\n",
      "0: 640x640 (no detections), 196.2ms\n",
      "Speed: 0.0ms preprocess, 196.2ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Results' object has no attribute 'size'. See valid attributes below.\n\n    A class for storing and manipulating inference results.\n\n    This class encapsulates the functionality for handling detection, segmentation, pose estimation,\n    and classification results from YOLO models.\n\n    Attributes:\n        orig_img (numpy.ndarray): Original image as a numpy array.\n        orig_shape (Tuple[int, int]): Original image shape in (height, width) format.\n        boxes (Boxes | None): Object containing detection bounding boxes.\n        masks (Masks | None): Object containing detection masks.\n        probs (Probs | None): Object containing class probabilities for classification tasks.\n        keypoints (Keypoints | None): Object containing detected keypoints for each object.\n        obb (OBB | None): Object containing oriented bounding boxes.\n        speed (Dict[str, float | None]): Dictionary of preprocess, inference, and postprocess speeds.\n        names (Dict[int, str]): Dictionary mapping class IDs to class names.\n        path (str): Path to the image file.\n        _keys (Tuple[str, ...]): Tuple of attribute names for internal use.\n\n    Methods:\n        update: Updates object attributes with new detection results.\n        cpu: Returns a copy of the Results object with all tensors on CPU memory.\n        numpy: Returns a copy of the Results object with all tensors as numpy arrays.\n        cuda: Returns a copy of the Results object with all tensors on GPU memory.\n        to: Returns a copy of the Results object with tensors on a specified device and dtype.\n        new: Returns a new Results object with the same image, path, and names.\n        plot: Plots detection results on an input image, returning an annotated image.\n        show: Shows annotated results on screen.\n        save: Saves annotated results to file.\n        verbose: Returns a log string for each task, detailing detections and classifications.\n        save_txt: Saves detection results to a text file.\n        save_crop: Saves cropped detection images.\n        tojson: Converts detection results to JSON format.\n\n    Examples:\n        >>> results = model(\"path/to/image.jpg\")\n        >>> for result in results:\n        ...     print(result.boxes)  # Print detection boxes\n        ...     result.show()  # Display the annotated image\n        ...     result.save(filename=\"result.jpg\")  # Save annotated image\n    ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[99], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m result_tensor \u001b[38;5;241m=\u001b[39m y[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Use the plot method to visualize the results\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[43mmake_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/etudiant/New D/PyTorchSRC/.venv/lib/python3.12/site-packages/torchviz/dot.py:163\u001b[0m, in \u001b[0;36mmake_dot\u001b[0;34m(var, params, show_attrs, show_saved, max_attr_chars)\u001b[0m\n\u001b[1;32m    161\u001b[0m         add_base_tensor(v)\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     \u001b[43madd_base_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m resize_graph(dot)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dot\n",
      "File \u001b[0;32m/media/etudiant/New D/PyTorchSRC/.venv/lib/python3.12/site-packages/torchviz/dot.py:149\u001b[0m, in \u001b[0;36mmake_dot.<locals>.add_base_tensor\u001b[0;34m(var, color)\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    148\u001b[0m seen\u001b[38;5;241m.\u001b[39madd(var)\n\u001b[0;32m--> 149\u001b[0m dot\u001b[38;5;241m.\u001b[39mnode(\u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mid\u001b[39m(var)), \u001b[43mget_var_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m)\u001b[49m, fillcolor\u001b[38;5;241m=\u001b[39mcolor)\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (var\u001b[38;5;241m.\u001b[39mgrad_fn):\n\u001b[1;32m    151\u001b[0m     add_nodes(var\u001b[38;5;241m.\u001b[39mgrad_fn)\n",
      "File \u001b[0;32m/media/etudiant/New D/PyTorchSRC/.venv/lib/python3.12/site-packages/torchviz/dot.py:94\u001b[0m, in \u001b[0;36mmake_dot.<locals>.get_var_name\u001b[0;34m(var, name)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m name:\n\u001b[1;32m     93\u001b[0m     name \u001b[38;5;241m=\u001b[39m param_map[\u001b[38;5;28mid\u001b[39m(var)] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mid\u001b[39m(var) \u001b[38;5;129;01min\u001b[39;00m param_map \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 94\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (name, size_to_str(\u001b[43mvar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m()))\n",
      "File \u001b[0;32m/media/etudiant/New D/PyTorchSRC/.venv/lib/python3.12/site-packages/ultralytics/utils/__init__.py:219\u001b[0m, in \u001b[0;36mSimpleClass.__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Custom attribute access error message with helpful information.\"\"\"\u001b[39;00m\n\u001b[1;32m    218\u001b[0m name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m--> 219\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. See valid attributes below.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Results' object has no attribute 'size'. See valid attributes below.\n\n    A class for storing and manipulating inference results.\n\n    This class encapsulates the functionality for handling detection, segmentation, pose estimation,\n    and classification results from YOLO models.\n\n    Attributes:\n        orig_img (numpy.ndarray): Original image as a numpy array.\n        orig_shape (Tuple[int, int]): Original image shape in (height, width) format.\n        boxes (Boxes | None): Object containing detection bounding boxes.\n        masks (Masks | None): Object containing detection masks.\n        probs (Probs | None): Object containing class probabilities for classification tasks.\n        keypoints (Keypoints | None): Object containing detected keypoints for each object.\n        obb (OBB | None): Object containing oriented bounding boxes.\n        speed (Dict[str, float | None]): Dictionary of preprocess, inference, and postprocess speeds.\n        names (Dict[int, str]): Dictionary mapping class IDs to class names.\n        path (str): Path to the image file.\n        _keys (Tuple[str, ...]): Tuple of attribute names for internal use.\n\n    Methods:\n        update: Updates object attributes with new detection results.\n        cpu: Returns a copy of the Results object with all tensors on CPU memory.\n        numpy: Returns a copy of the Results object with all tensors as numpy arrays.\n        cuda: Returns a copy of the Results object with all tensors on GPU memory.\n        to: Returns a copy of the Results object with tensors on a specified device and dtype.\n        new: Returns a new Results object with the same image, path, and names.\n        plot: Plots detection results on an input image, returning an annotated image.\n        show: Shows annotated results on screen.\n        save: Saves annotated results to file.\n        verbose: Returns a log string for each task, detailing detections and classifications.\n        save_txt: Saves detection results to a text file.\n        save_crop: Saves cropped detection images.\n        tojson: Converts detection results to JSON format.\n\n    Examples:\n        >>> results = model(\"path/to/image.jpg\")\n        >>> for result in results:\n        ...     print(result.boxes)  # Print detection boxes\n        ...     result.show()  # Display the annotated image\n        ...     result.save(filename=\"result.jpg\")  # Save annotated image\n    "
     ]
    }
   ],
   "source": [
    "# plot the model_3\n",
    "from torchviz import make_dot\n",
    "from torch.autograd import Variable\n",
    "\n",
    "x = Variable(torch.randn(1, 3, 640, 640))\n",
    "y = model_2.predict(source=x)\n",
    "\n",
    "# Extract the first result tensor from the list\n",
    "result_tensor = y[0]\n",
    "\n",
    "# Use the plot method to visualize the results\n",
    "make_dot(result_tensor, params=dict(model_2.state_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
