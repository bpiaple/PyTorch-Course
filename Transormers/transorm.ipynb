{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-torch.log(torch.tensor(10000.0)) / d_model))\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:x.size(0), :]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScaledDotProductAttention(nn.Module):\n",
    "    def __init__(self, d_k):\n",
    "        super(ScaledDotProductAttention, self).__init__()\n",
    "        self.d_k = d_k\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        scores = torch.matmul(Q, K.transpose(-2, -1)) / torch.sqrt(torch.tensor(self.d_k).float()) \n",
    "        scores.masked_fill_(attn_mask == 0, -1e9) \n",
    "        attn = softmax(scores, dim=-1)\n",
    "        context = torch.matmul(attn, V)\n",
    "        return context, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.n_heads = n_heads\n",
    "        self.d_k = d_model // n_heads\n",
    "        self.d_v = d_model // n_heads\n",
    "\n",
    "        self.W_Q = nn.Linear(d_model, d_model)\n",
    "        self.W_K = nn.Linear(d_model, d_model)\n",
    "        self.W_V = nn.Linear(d_model, d_model)\n",
    "        self.linear = nn.Linear(n_heads * self.d_v, d_model)\n",
    "\n",
    "    def forward(self, Q, K, V, attn_mask):\n",
    "        batch_size = Q.size(0)\n",
    "        \n",
    "        Q = self.W_Q(Q).view(batch_size, -1, self.n_heads, self.d_k).transpose(1,2) \n",
    "        K = self.W_K(K).view(batch_size, -1, self.n_heads, self.d_k).transpose(1,2)\n",
    "        V = self.W_V(V).view(batch_size, -1, self.n_heads, self.d_v).transpose(1,2)\n",
    "        \n",
    "        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.n_heads, 1, 1) \n",
    "\n",
    "        context, attn = ScaledDotProductAttention(self.d_k)(Q, K, V, attn_mask)\n",
    "        context = context.transpose(1, 2).reshape(batch_size, -1, self.n_heads * self.d_v) \n",
    "        output = self.linear(context)\n",
    "        return output, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.pos_ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "        self.layer_norm1 = nn.LayerNorm(d_model)\n",
    "        self.layer_norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, inputs, enc_self_attn_mask):\n",
    "        outputs, attn = self.enc_self_attn(inputs, inputs, inputs, enc_self_attn_mask) \n",
    "        outputs = inputs + self.dropout1(outputs)\n",
    "        outputs = self.layer_norm1(outputs)\n",
    "        outputs = outputs + self.dropout2(self.pos_ffn(outputs)) \n",
    "        outputs = self.layer_norm2(outputs)\n",
    "        return outputs, attn\n",
    "\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout=0.1):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.dec_enc_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.pos_ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "        self.layer_norm1 = nn.LayerNorm(d_model)\n",
    "        self.layer_norm2 = nn.LayerNorm(d_model)\n",
    "        self.layer_norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        self.dropout3 = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, inputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask):\n",
    "        outputs, dec_self_attn = self.dec_self_attn(inputs, inputs, inputs, dec_self_attn_mask) \n",
    "        outputs = inputs + self.dropout1(outputs)\n",
    "        outputs = self.layer_norm1(outputs)\n",
    "        outputs, dec_enc_attn = self.dec_enc_attn(outputs, enc_outputs, enc_outputs, dec_enc_attn_mask)\n",
    "        outputs = outputs + self.dropout2(outputs)\n",
    "        outputs = self.layer_norm2(outputs)\n",
    "        outputs = outputs + self.dropout3(self.pos_ffn(outputs))\n",
    "        outputs = self.layer_norm3(outputs)\n",
    "\n",
    "        return outputs, dec_self_attn, dec_enc_attn\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, n_layers, n_heads, d_ff, dropout=0.1, max_len=5000):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.src_emb = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_emb = PositionalEncoding(d_model, max_len)\n",
    "        self.layers = nn.ModuleList([EncoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(n_layers)])\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, src_mask):\n",
    "        x = self.dropout(self.pos_emb(self.src_emb(x)))\n",
    "        enc_self_attns = []\n",
    "        for layer in self.layers:\n",
    "            x, enc_self_attn = layer(x, src_mask)\n",
    "            enc_self_attns.append(enc_self_attn)\n",
    "        return x, enc_self_attns\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, d_model, n_layers, n_heads, d_ff, dropout=0.1, max_len=5000):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.tgt_emb = nn.Embedding(vocab_size, d_model)\n",
    "        self.pos_emb = PositionalEncoding(d_model, max_len)\n",
    "        self.layers = nn.ModuleList([DecoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(n_layers)])\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    def forward(self, x, enc_outputs, src_mask, tgt_mask):\n",
    "        x = self.dropout(self.pos_emb(self.tgt_emb(x)))\n",
    "        dec_self_attns, dec_enc_attns = [], []\n",
    "        for layer in self.layers:\n",
    "            x, dec_self_attn, dec_enc_attn = layer(x, enc_outputs, tgt_mask, src_mask)\n",
    "            dec_self_attns.append(dec_self_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "        return x, dec_self_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, n_layers, n_heads, d_ff, dropout=0.1, max_len=5000):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = Encoder(src_vocab_size, d_model, n_layers, n_heads, d_ff, dropout, max_len)\n",
    "        self.decoder = Decoder(tgt_vocab_size, d_model, n_layers, n_heads, d_ff, dropout, max_len)\n",
    "        self.projection = nn.Linear(d_model, tgt_vocab_size, bias=False)\n",
    "\n",
    "    def forward(self, enc_inputs, dec_inputs, src_mask, tgt_mask):\n",
    "        enc_outputs, enc_self_attns = self.encoder(enc_inputs, src_mask)\n",
    "        dec_outputs, dec_self_attns, dec_enc_attns = self.decoder(dec_inputs, enc_outputs, src_mask, tgt_mask)\n",
    "        dec_logits = self.projection(dec_outputs) \n",
    "        return dec_logits.view(-1, dec_logits.size(-1)), enc_self_attns, dec_self_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparamètres\n",
    "d_model = 512  # Dimension du modèle\n",
    "n_layers = 6  # Nombre de couches dans l'encodeur et le décodeur\n",
    "n_heads = 8  # Nombre de têtes d'attention\n",
    "d_ff = 2048  # Dimension de la couche feed-forward\n",
    "src_vocab_size = 8192  # Taille du vocabulaire source\n",
    "tgt_vocab_size = 8192  # Taille du vocabulaire cible\n",
    "\n",
    "# Instancier le modèle\n",
    "model = Transformer(src_vocab_size, tgt_vocab_size, d_model, n_layers, n_heads, d_ff)\n",
    "\n",
    "# ... (Code pour créer les masques src_mask et tgt_mask, \n",
    "#      charger les données d'entraînement, définir la fonction de coût,\n",
    "#      l'optimiseur, etc.)\n",
    "\n",
    "# Boucle d'entraînement (simplifiée)\n",
    "# for epoch in range(num_epochs):\n",
    "#     for enc_inputs, dec_inputs, src_mask, tgt_mask in train_loader:\n",
    "#         # ... (Code pour calculer la sortie du modèle, la fonction de coût,\n",
    "#         #      mettre à jour les paramètres du modèle, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Transformer(src_vocab_size, tgt_vocab_size, d_model, n_layers, n_heads, d_ff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'transformer.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'attached.svg'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot the model\n",
    "from torchviz import make_dot\n",
    "enc_inputs = torch.tensor([[1, 2, 3, 4, 5]])\n",
    "dec_inputs = torch.tensor([[1, 2, 3, 4, 5]])\n",
    "src_mask = torch.tensor([[1, 1, 1, 1, 1]])\n",
    "tgt_mask = torch.tensor([[1, 1, 1, 1, 1]])\n",
    "out = model(enc_inputs, dec_inputs, src_mask, tgt_mask)\n",
    "make_dot(out[0], params=dict(model.named_parameters()))\n",
    "\n",
    "# Afficher le graphique\n",
    "make_dot(out[0], params=dict(model.named_parameters()), show_attrs=True).render(\"attached\", format=\"svg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher le graphique\n",
    "# make_dot(out[0], params=dict(model.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.parameters of Transformer(\n",
       "  (encoder): Encoder(\n",
       "    (src_emb): Embedding(8192, 512)\n",
       "    (pos_emb): PositionalEncoding()\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x EncoderLayer(\n",
       "        (enc_self_attn): MultiHeadAttention(\n",
       "          (W_Q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (W_K): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (W_V): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (pos_ffn): PoswiseFeedForwardNet(\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (tgt_emb): Embedding(8192, 512)\n",
       "    (pos_emb): PositionalEncoding()\n",
       "    (layers): ModuleList(\n",
       "      (0-5): 6 x DecoderLayer(\n",
       "        (dec_self_attn): MultiHeadAttention(\n",
       "          (W_Q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (W_K): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (W_V): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (dec_enc_attn): MultiHeadAttention(\n",
       "          (W_Q): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (W_K): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (W_V): Linear(in_features=512, out_features=512, bias=True)\n",
       "          (linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (pos_ffn): PoswiseFeedForwardNet(\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (relu): ReLU()\n",
       "        )\n",
       "        (layer_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (layer_norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.1, inplace=False)\n",
       "        (dropout2): Dropout(p=0.1, inplace=False)\n",
       "        (dropout3): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (projection): Linear(in_features=512, out_features=8192, bias=False)\n",
       ")>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
